{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5017574a-fa68-4c5b-b31d-dce65f15a6b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import fwiVis.fwiVis as fv\n",
    "import s3fs\n",
    "s3 = s3fs.S3FileSystem(anon=False)\n",
    "from math import cos, asin, sqrt\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import rioxarray as rio\n",
    "import xarray as xr\n",
    "import rasterio\n",
    "import glob\n",
    "from shapely.errors import ShapelyDeprecationWarning\n",
    "from shapely.geometry import Point\n",
    "from shapely import unary_union\n",
    "import warnings\n",
    "import folium\n",
    "import datetime\n",
    "import time\n",
    "from folium import plugins\n",
    "warnings.filterwarnings(\"ignore\", category=ShapelyDeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=ShapelyDeprecationWarning) \n",
    "import contextily as cx\n",
    "from shapely.geometry import box\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import chain\n",
    "\n",
    "from datetime import date\n",
    "from shapely.geometry import MultiPolygon\n",
    "\n",
    "\n",
    "sys.path.insert(0, '/projects/old_shared/fire_weather_vis/base-fwi-vis/')\n",
    "import fwiVis.fwiVis as fv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e789fa-fbaf-4949-8bb9-d584e34eed4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remerge_largefire(fires):\n",
    "    '''\n",
    "    If two final feds perimeters intersect spatialy, check if one ended before the other began. If yes, give it the ID of the earlier perimeter. \n",
    "    Note: Could optionally be spitting out time differences, or sorting by them. For Quebec, was a max of 22 days, min of 1 day. Theoretically, not sure why the 1 day perimeter wasn't merged by feds. \n",
    "    '''\n",
    "    # Get an id, first/ last t per ID, and a geometry\n",
    "    first_perims = fires[~fires.geometry.isnull()].groupby(\"fireID\").t.min().reset_index()\n",
    "    last_perims = fires[~fires.geometry.isnull()].groupby(\"fireID\").t.max().reset_index()\n",
    "    plot_last = fires.merge(last_perims, on = [\"fireID\", \"t\"], how = 'right')\n",
    "    plot_first = fires.merge(first_perims, on = [\"fireID\", \"t\"], how = 'right')\n",
    "    plot_last = plot_last[[\"fireID\", \"t\", \"geometry\"]]\n",
    "    plot_first = plot_first[[\"fireID\", \"t\", \"geometry\"]]\n",
    "                    \n",
    "    # Check what perimeters spatially intersect into anouther one through time\n",
    "    last_in_last = plot_last.sjoin(plot_last, how = \"left\", predicate = \"intersects\")\n",
    "    lil = last_in_last.groupby([\"fireID_left\",]).t_right.min().reset_index()\n",
    "    id_with_max_time = lil.merge(last_in_last[[\"t_right\", \"t_left\", \"geometry\", \"fireID_right\", \"fireID_left\"]], on = [\"t_right\", \"fireID_left\"], how = \"right\")\n",
    "\n",
    "    id_with_max_time = id_with_max_time.rename(columns={\"fireID_right\": \"mergeID\", \n",
    "                                     \"fireID_left\" :\"fireID\",\n",
    "                                     \"t_right\":\"mergeID_t\",\n",
    "                                     \"t_left\":\"fireID_end_t\"\n",
    "    })\n",
    "\n",
    "    id_with_max_time_check = id_with_max_time[id_with_max_time.fireID_end_t < id_with_max_time.mergeID_t]\n",
    "\n",
    "    ### FireID the earlier perimeter that later perimeters are merged into. \"mergeID\" describes the merge-ey ## I actually think this is wrong. I think I made it so the \"fireID\" is what is merged into the \"mergeID\"\n",
    "    fireID_with_merge = id_with_max_time_check.groupby([\"fireID\"]).mergeID.unique().reset_index() \n",
    "    #print(fireID_with_merge)\n",
    "\n",
    "    mergeID_with_fireID  = id_with_max_time_check.groupby([\"mergeID\"]).fireID.unique().reset_index()\n",
    "    #print(mergeID_with_fireID)\n",
    "                    \n",
    "    # Check when the fireID and mergeID started/stopped. \n",
    "    get_merge_start = plot_first[[\"fireID\", \"t\"]].rename(columns={\"fireID\":\"mergeID\", \n",
    "                                                           \"t\":\"mergeID_start_t\"})\n",
    "    #print(get_merge_start)\n",
    "    get_fireID_start =  plot_first[[\"fireID\", \"t\"]].rename(columns={ \"t\":\"fireID_start_t\"})\n",
    "    #print(get_fireID_start)\n",
    "\n",
    "    id_map = id_with_max_time_check.merge(get_merge_start, on = [\"mergeID\"])\n",
    "    id_map = id_map.merge(get_fireID_start, on = [\"fireID\"])\n",
    "    id_map = id_map[[\"fireID\",\"fireID_start_t\",  \"fireID_end_t\", \"mergeID\", \"mergeID_start_t\", \"mergeID_t\"]]\n",
    "    id_map[\"time_diff_fireIDend_mergeIDstart\"] = id_map.fireID_end_t.astype('datetime64[ns]') - id_map.mergeID_start_t.astype('datetime64[ns]') ## Negative means that mergeID started after fireID ended\n",
    "    #print(id_map)\n",
    "    # Below code is just for isolateing perimeters that ended before the later perimetetr began. This is useful for identifying places where the assumptino to invalidate a fire after five days might be wrong. \n",
    "#     # Subset to IDs where one fire \"ended\" before the next fire began                \n",
    "#     only_IDs_with_negative_dates = id_map[id_map.time_diff_fireIDend_mergeIDstart.dt.days < 0]\n",
    "    \n",
    "#     # Go through an reindex just the IDs that overlap in space but not time                \n",
    "#     fires[\"old_id\"] = \"\"\n",
    "#     fire_ids = only_IDs_with_negative_dates.mergeID.unique() ## Gives the IDs of fires to be merged into anouther fire\n",
    "\n",
    "#     for i in fire_ids:\n",
    "#         print(\"start: \")\n",
    "#         print(fire_ids)\n",
    "#         min_t = id_with_max_time_check[id_with_max_time_check.mergeID == i].fireID_end_t.min()\n",
    "#         print(min_t)\n",
    "#         sm_id_map = id_with_max_time_check[(id_with_max_time_check.mergeID == i) & (id_with_max_time_check.fireID_end_t == min_t)]\n",
    "#         print(sm_id_map.fireID.values)\n",
    "#         if(len(sm_id_map) == 0):\n",
    "#             print(\"ID\", i, \" only merges with self\")\n",
    "#             fires[\"old_id\"][fires.fireID == i] = i\n",
    "#         else:\n",
    "#             if(len(sm_id_map) != 1):\n",
    "#                 print(\"There are two perimeters that intersect with ID\",i, \" that started at the same time.\")\n",
    "#                 print(sm_id_map)\n",
    "#                 break\n",
    "\n",
    "#             fires[\"old_id\"][fires.fireID == i] = i\n",
    "#             fires[\"fireID\"][fires.fireID == i] = str(*sm_id_map.fireID.values)\n",
    "                    \n",
    "#     #return(fires)\n",
    "    return(id_map)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2049734-ada6-4ca7-a938-e8ad185895ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = \"/projects/old_shared/fire_weather_vis/Lightning_analysis/fwi_timeline_merge/Final_dataset_as_of_20240209.csv\" \n",
    "fires = fv.prep_fire_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918e5fd7-4b24-4344-ad66-16417a0de686",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fires = fires[fires.InterCloud.isna()]\n",
    "fires.t = pd.to_datetime(fires.t, format='ISO8601')\n",
    "new_fires = remerge_largefire(fires)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeefc76-c025-4412-9ca3-554eea9b80f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## How to merge shapes\n",
    "\n",
    "#shapely.MultiPolgyon(fires.iloc[100].geometry,  fires.iloc[104].geometry)\n",
    "\n",
    "\n",
    "test_polygon = MultiPolygon([fires.iloc[100].geometry,  fires.iloc[104].geometry])\n",
    "\n",
    "test_polygon = MultiPolygon(fires[~fires.geometry.isna()].geometry.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eec0cdc-1561-4fb1-8a8a-e28280b06a50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#MultiPolygon(fires[~fires.geometry.isna()].geometry.values)\n",
    "\n",
    "#MultiPolygon([*fires[~fires.geometry.isna()].geometry.values])\n",
    "#unary_union(fires[~fires.geometry.isna()].geometry)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2fde2b-b326-42af-9fa1-5d307e4e4f11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_fires_into(newfire, fires):\n",
    "    '''\n",
    "    newfire [DataFrame] output from remerge_largefire. \n",
    "    fires [GeoDataFrame] geodataframe of all largefires. \n",
    "    '''\n",
    "    fires = fires[~fires.geometry.isna()]\n",
    "    print(\"Removing full timeseries of met data.\")\n",
    "    remake_fires = fires.copy() ## Need to do this? \n",
    "    remake_fires[\"composit_ids\"] = \"\"\n",
    "    remake_fires[\"rows_edited\"] = False ## Will be none if fire doesn'ge merge into a different fire\n",
    "\n",
    "    fires.t = fires.t.astype(\"datetime64[ns]\")\n",
    "    separator = ', '\n",
    "    #fires[\"modified_id\"] = fires.fireID\n",
    "    #newfire = newfire.sort_values(by = [\"fireID\", \"fireID_start_t\"])\n",
    "    #newfire.mergeID_start_t = newfire.mergeID_start_t.astype(\"datetime64[ns]\")\n",
    "    #newfire.mergeID_t = newfire.mergeID_t.astype(\"datetime64[ns]\")\n",
    "    for m in newfire.mergeID.unique(): ### For each id that had something merged into it\n",
    "        fireIDs = newfire[newfire.mergeID == m].fireID.unique() ## Get all the fireID of things that were merged into it\n",
    "        row_mask = (fires.fireID.isin(fireIDs) | fires.fireID.isin([m]) ) ## Get the IDs that will merge into m and m\n",
    "        #print(row_mask)\n",
    "        times = fires[row_mask].t.unique()\n",
    "        #print(len(times))\n",
    "       # print(m)\n",
    "        for t in times:\n",
    "            #print(t)\n",
    "            row_mask_f = (row_mask) & (fires.t.astype(\"str\") == str(t))\n",
    "            row_mask_t = (remake_fires.fireID == m) & (remake_fires.t.astype(\"str\") == str(t))\n",
    "            row_mask_any_t =  (remake_fires.fireID.isin(fireIDs) | remake_fires.fireID.isin([m]) ) & (remake_fires.t.astype(\"str\") == str(t))\n",
    "            if row_mask_f.any():  # Check if any rows match row_mask_t\n",
    "                #print(f\"Updating rows for fireID: {m}, time: {t}\")\n",
    "                remake_fires.loc[row_mask_any_t, \"geometry\"] = unary_union(fires[row_mask_f].geometry)\n",
    "                remake_fires.loc[row_mask_any_t, \"farea\"] = fires.loc[row_mask_f, \"farea\"].sum()\n",
    "                remake_fires.loc[row_mask_any_t, \"fperim\"] = fires.loc[row_mask_f, \"fperim\"].sum()\n",
    "                remake_fires.loc[row_mask_any_t, \"n_pixels\"] = fires.loc[row_mask_f, \"n_pixels\"].sum()\n",
    "                remake_fires.loc[row_mask_any_t, \"n_newpixels\"] = fires.loc[row_mask_f, \"n_newpixels\"].sum()\n",
    "                remake_fires.loc[row_mask_any_t, \"flinelen\"] = fires.loc[row_mask_f, \"flinelen\"].sum()\n",
    "                remake_fires.loc[row_mask_any_t, \"duration\"] = fires.loc[row_mask_f, \"duration\"].max()\n",
    "                remake_fires.loc[row_mask_any_t, \"pixden\"] = fires.loc[row_mask_f, \"n_newpixels\"].sum() / fires.loc[row_mask_f, \"farea\"].sum()\n",
    "                remake_fires.loc[row_mask_any_t, \"meanFRP\"] = (fires.loc[row_mask_f, \"meanFRP\"] * fires.loc[row_mask_f, \"farea\"]).sum() / fires.loc[row_mask_f, \"farea\"].sum()\n",
    "                remake_fires.loc[row_mask_any_t, \"composit_ids\"] = separator.join(fires.loc[row_mask_f, \"fireID\"].unique())\n",
    "                remake_fires.loc[row_mask_any_t, \"rows_edited\"] = \"edited\"\n",
    "                remake_fires.loc[row_mask_any_t, \"fireID\"] = m\n",
    "            else:\n",
    "                #print(\"entering into the else\")\n",
    "                remake_fires.loc[row_mask_any_t, \"rows_edited\"] = f\"No row of {m} at {t}\"\n",
    "    \n",
    "     \n",
    "    # fires_with_other_fires = newfire.mergeID.unique()\n",
    "    # fires_that_didnt_merge = fires[~(fires.fireID.isin(new_fires.fireID) |fires.fireID.isin(new_fires.mergeID)) ].fireID.unique()\n",
    "    # remake_fires = remake_fires[(remake_fires.fireID.isin(fires_with_other_fires)) |  fires_that_didnt_merge] ## Drop the IDs that will only be merged into something else\n",
    "    remake_fires = remake_fires[~remake_fires.fireID.isin(newfire.fireID)] ## Drop the IDs that will only be merged into something else\n",
    "    \n",
    "    return(remake_fires)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595f27b2-11c8-4a0a-b74b-4ce52fe7065f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fires[(fires.fireID == \"10713\") & (fires.t.astype(\"str\") == \"2023-07-16 00:00:00\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464a4625-94a0-4784-80d1-94f668ecf8aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test =  merge_fires_into(new_fires, fires)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3d8642-7f70-4ed6-9355-96ac12e1b0f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.composit_ids.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e908baaa-0b7c-402b-b6a0-56e250fffe96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test[test.composit_ids.str.contains('12595')].fireID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfcecff-a101-4706-944c-c3fcdc898986",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test[test.fireID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f7323f-64ed-421d-b3f2-fa6ed22561a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(fires.fireID.unique()))\n",
    "print(len(test.fireID.unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a419edc3-90fc-407b-8f88-61a6d8002994",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_fires[new_fires.fireID.isin(new_fires.mergeID)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65edff0a-6435-4bdd-8695-71a425a357f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5030dae0-5287-4c96-8045-3fcd89055e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# large_8495 = fv.load_large_fire(\"8495\", \"2023\", \"BOREAL_NRT_3571_DPS\", layer = \"nfplist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35609e20-b9c2-4b39-8aa2-271b1b628046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# large_8505 = fv.load_large_fire(\"8505\", \"2023\", \"BOREAL_NRT_3571_DPS\", layer = \"nfplist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3b2703-80d8-4302-80b9-c43c2cfd1b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# large_8505.t = large_8505.t.astype(\"str\")\n",
    "# large_8505.datetime = large_8505.datetime.astype(\"str\")\n",
    "\n",
    "# large_8495.t = large_8495.t.astype(\"str\")\n",
    "# large_8495.datetime = large_8495.datetime.astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc95a6c-a413-47e0-9ff8-4156e914a352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7febd299-d428-47a4-8b07-3444d07abbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ### Checking to see if the numbers for the cummulative statistics are wrong (ie, how are the number of pixels added in before the merge? after the merge?)\n",
    "\n",
    "# fires.t = fires.t.astype(\"str\")\n",
    "\n",
    "# # 8645\n",
    "# foi = '8495'\n",
    "\n",
    "# bbox = fires[(fires.fireID == foi) & (~fires.geometry.isna()) & (fires.t == fires[(fires.fireID == foi) & (~fires.geometry.isna())].t.max())].bounds\n",
    "# #fires.t = fires.t.astype(\"datetime64[ns]\")\n",
    "# #fires = fires.sort_values(by = \"t\", ascending= False)\n",
    "# #fires.t = fires.t.astype(\"str\")\n",
    "\n",
    "# #some_ids = fires.loc[(fires.t <= \"2023-06-05\"), ['fireID', 't', \"n_pixels\", 'geometry']].cx[bbox.values[0][0]:bbox.values[0][2], bbox.values[0][1]:bbox.values[0][3]].fireID.unique()\n",
    "# m = fires.loc[(fires.t <= \"2023-06-05\"), ['fireID', 't', \"n_pixels\", \"n_newpixels\", 'geometry']].cx[bbox.values[0][0]:bbox.values[0][2], bbox.values[0][1]:bbox.values[0][3]].explore(style_kwds = {\"fillOpacity\": 0}, column = \"fireID\")\n",
    "# m = large_8495[large_8495.t <= \"2023-06-05\"].explore(m = m)\n",
    "# m = large_8505[large_8505.t <= \"2023-06-05\"].explore(m = m, color = \"light blue\")\n",
    "# m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89569c87-ffd6-430d-9f17-e6b58012f565",
   "metadata": {},
   "outputs": [],
   "source": [
    " ### Checking to see if the numbers for the cummulative statistics are wrong (ie, how are the number of pixels added in before the merge? after the merge?)\n",
    "fires.t = fires.t.astype(\"datetime64[ns]\")\n",
    "fires = fires.sort_values(by = \"t\", ascending = False)\n",
    "fires.t = fires.t.astype(\"str\")\n",
    "\n",
    "# 8645\n",
    "foi = '8495'\n",
    "\n",
    "bbox = fires[(fires.fireID == foi) & (~fires.geometry.isna()) & (fires.t == fires[(fires.fireID == foi) & (~fires.geometry.isna())].t.max())].bounds\n",
    "#fires.t = fires.t.astype(\"datetime64[ns]\")\n",
    "#fires = fires.sort_values(by = \"t\", ascending= False)\n",
    "#fires.t = fires.t.astype(\"str\")\n",
    "\n",
    "#some_ids = fires.loc[(fires.t <= \"2023-06-05\"), ['fireID', 't', \"n_pixels\", 'geometry']].cx[bbox.values[0][0]:bbox.values[0][2], bbox.values[0][1]:bbox.values[0][3]].fireID.unique()\n",
    "m = fires[['fireID', 't', \"n_pixels\", \"n_newpixels\", 'geometry']].cx[bbox.values[0][0]:bbox.values[0][2], bbox.values[0][1]:bbox.values[0][3]].explore(style_kwds = {\"fillOpacity\": 0}, column = \"fireID\")\n",
    "#m = large_8495[large_8495.t <= \"2023-06-05\"].explore(m = m)\n",
    "#m = large_8505[large_8505.t <= \"2023-06-05\"].explore(m = m, color = \"light blue\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec55391-1533-4d15-ab38-d8fdd531fd98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.t.astype(\"datetime64[ns]\")\n",
    "test = test.sort_values(by = \"t\", ascending = False)\n",
    "\n",
    "test = test[['fireID', 't', 'geometry', 'n_pixels', 'n_newpixels',\n",
    "       'farea', 'fperim', 'flinelen', 'duration', 'pixden', 'meanFRP',\n",
    "       'lon_centroid', 'lat_centroid', 'GEOS-5.IMERGEARLY',\n",
    "       'FWI','composit_ids']]\n",
    "test.t = test.t.astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe703a6-b044-4324-a846-cd776fca78db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54ebcbe-5780-4f43-b6bb-0105f2bc56ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test[(test.fireID == \"8495\")].explore(style_kwds = {\"fillOpacity\": 0}, column = \"fireID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e4afd6-49a8-4f84-9374-89deb2b085ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_no_na = test.dropna()\n",
    "test_no_na[test_no_na.composit_ids.str.contains('12596')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f466f0ea-b030-4c81-883c-016af225c7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test.composit_ids.str.contains('12595')].fireID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d78e38-b2b9-44e4-8dd9-c2a55c9ccb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf6581a-7085-43c9-a337-2fed958d66bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#foi = '12595'\n",
    "foi = '15929'\n",
    "#foi = '16062'\n",
    "\n",
    "test.t = test.t.astype(\"str\")\n",
    "\n",
    "bbox = test[(test.fireID == foi) & (~test.geometry.isna()) & (test.t == test[(test.fireID == foi) & (~test.geometry.isna())].t.max())].bounds\n",
    "#test.t = test.t.astype(\"datetime64[ns]\")\n",
    "#test = test.sort_values(by = \"t\", ascending= False)\n",
    "#test.t = test.t.astype(\"str\")\n",
    "\n",
    "#some_ids = test.loc[(test.t <= \"2023-06-05\"), ['fireID', 't', \"n_pixels\", 'geometry']].cx[bbox.values[0][0]:bbox.values[0][2], bbox.values[0][1]:bbox.values[0][3]].fireID.unique()\n",
    "#m = test[['fireID', \"t\",  \"n_pixels\", \"n_newpixels\", 'geometry']].cx[bbox.values[0][0]:bbox.values[0][2], bbox.values[0][1]:bbox.values[0][3]].explore(style_kwds = {\"fillOpacity\": 0}, column = \"fireID\")\n",
    "#m = large_8495[large_8495.t <= \"2023-06-05\"].explore(m = m)\n",
    "#m = large_8505[large_8505.t <= \"2023-06-05\"].explore(m = m, color = \"light blue\")\n",
    "#m\n",
    "test.loc[(test.fireID == foi) & (~test.geometry.isna()), ['fireID', 't', 'geometry', 'composit_ids', 'rows_edited']].explore(style_kwds = {\"fillOpacity\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a475b2-4af3-44ae-b50b-3917ffbe8318",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(len(large_8505[large_8505.t <= \"2023-06-03 00:00:00\"]))\n",
    "#print(len(large_8495[large_8495.t <= \"2023-06-03 00:00:00\"])) ## Before merge pixels are counted seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13753602-baf6-4ecc-a396-451626ac04d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(len(large_8495[large_8495.t <= \"2023-06-03 12:00:00\"])) ### NUmber of pixels post-merge represents the cummulative of the smaller plus the commulative of the bigger fire. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72186886-389a-48b2-b19a-07f242b8681a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "What the above code tells me is that up untill the moment of the merge, the perimeters are treated seperately, but one the merge happens they are counted together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f00eeb7-49e3-48fd-a672-56eb25833435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sml = 4 + 8 + 7 + 3\n",
    "\n",
    "big = 1 + 6 +100 + 5 + 9 + 1 + 4 + 8\n",
    "\n",
    "print(big / 8)\n",
    "\n",
    "print(sml / 4)\n",
    "\n",
    "print((big / 8) + (sml / 4))\n",
    "print((big + sml)/ 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0fc925-158b-4b93-8663-7679a75398b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\t8244\n",
    "\n",
    "\n",
    "foi = '12595'\n",
    "\n",
    "bbox = fires[(fires.fireID == foi) & (~fires.geometry.isna()) & (fires.t == fires[(fires.fireID == foi) & (~fires.geometry.isna())].t.max())].bounds\n",
    "fires.t = fires.t.astype(\"datetime64[ns]\")\n",
    "fires = fires.sort_values(by = \"t\", ascending= False)\n",
    "fires.t = fires.t.astype(\"str\")\n",
    "\n",
    "some_ids = fires[['fireID', 't', 'geometry']].cx[bbox.values[0][0]:bbox.values[0][2], bbox.values[0][1]:bbox.values[0][3]].fireID.unique()\n",
    "print(some_ids)\n",
    "fires[['fireID', 't', 'geometry']].cx[bbox.values[0][0]:bbox.values[0][2], bbox.values[0][1]:bbox.values[0][3]].explore(style_kwds = {\"fillOpacity\": 0}, column = \"fireID\")\n",
    "\n",
    "\n",
    "#fires.loc[(fires.fireID == foi) & (~fires.geometry.isna()) & (fires.t == fires[(fires.fireID == foi) & (~fires.geometry.isna())].t.max()), ['fireID', 't', 'geometry']].explore(style_kwds = {\"fillOpacity\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b9cec6-5f88-409a-af3f-b27f18cee960",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_fires[new_fires.mergeID.isin(some_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3155897-63a9-44c7-aab8-2133eda42da3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = '15929'\n",
    "newfire = new_fires\n",
    "fires = fires[~fires.geometry.isna()]\n",
    "\n",
    "\n",
    "remake_fires = fires[~fires.geometry.isna()].copy() ## Need to do this? \n",
    "remate_fires = remake_fires.sort_values(by = \"t\", ascending = False)\n",
    "remake_fires[\"composit_ids\"] = None\n",
    "remake_fires[\"rows_edited\"] = None\n",
    "separator = ', '\n",
    "\n",
    "fireIDs = newfire[newfire.mergeID == m].fireID.unique() ## Get all the fireID of things that were merged into it\n",
    "row_mask = (fires.fireID.isin(fireIDs) | fires.fireID.isin([m]) ) ## Get the IDs that will merge into m and m\n",
    "#print(row_mask)\n",
    "fires = fires.sort_values(by = \"t\")\n",
    "times = fires[row_mask].t.unique()\n",
    "print(f\"Min time is {min(times)}, max time is {max(times)} \")\n",
    "for t in times:\n",
    "    #print(t)\n",
    "    row_mask_f = (row_mask) & (fires.t.astype(\"str\") == str(t))\n",
    "    row_mask_any_t =  (remake_fires.fireID.isin(fireIDs) | remake_fires.fireID.isin([m]) ) & (remake_fires.t.astype(\"str\") == str(t))\n",
    "    row_mask_t = (remake_fires.fireID == m) & (remake_fires.t.astype(\"str\") == str(t))\n",
    "    if row_mask_f.any():  # Check if any rows match row_mask_t\n",
    "        #print(f\"Updating rows for fireID: {m}, time: {t}\")\n",
    "        print(f\"At time {t}, IDs {fires[row_mask_f].fireID.unique()} were present.\")\n",
    "       \n",
    "        remake_fires.loc[row_mask_any_t, \"geometry\"] = unary_union(fires[row_mask_f].geometry) ## This line only works if there is already a row with m @ time t\n",
    "        remake_fires[row_mask_any_t].plot(facecolor = \"None\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "       \n",
    "\n",
    "    else:\n",
    "        print(\"entering into the else\")\n",
    "        remake_fires.loc[row_mask_t, \"rows_edited\"] = f\"No row of {m} at {t}\"\n",
    "\n",
    "#new_fires[new_fires.mergeID.isin(['12595'])].fireID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcc0654-d516-48e1-ad54-e93bc35043bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fires.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f06b54-ae1d-4345-84de-60c7221a2854",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fires[fires.fireID == \"8495\"].plot(facecolor = \"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd34560-eeb7-4a7b-8f39-3ad05af13fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fireatlas_oct4_2)",
   "language": "python",
   "name": "fireatlas_oct4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
